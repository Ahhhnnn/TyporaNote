# 以往面经查看

## TreeSet & HashSet的区别

1、实现方式，HashSet 哈希表，TreeSet 红黑树

2、都不允许存相同的对象，这个相同由自己定义，HashSet通过重写对象的equail和hashcode方法，TreeSet通过类实现Comparable接口，获取将比较对象作为TreeSet的构造函数参数传入

3、HashSet数据无序，TreeSet有序，可使用LinkedHashSet 实现有序

4、存取数据时间复杂度不同，HashSet  O（1） TreeSet 自平衡的二叉树 O（logn）

## 多个线程等到某个节点，统一放行的方式

？？ 没太懂

考 join方法？

还是countLatch（减少）  cylicBarrier（增加）

## CAP了解吗？Redis中的CAP

Consistency (一致性)

Availability (可用性)

Partition Tolerance (分区容错性)

只能保证其中的两个，P必须保证，所以必须选择A or C



Redis的**单机版本**中，由于只有一个Master节点，所有客户端都是访问一个Master节点，不会出现数据不一致问题，保证了C**强一致性**，如果出现单点故障，那么Master节点直接挂掉，所有客户端都不可访问，那么就会不可用，牺牲了**A可用性**



Redis 集群Cluster，变成了分布式NoSQL数据库，CAP模型也从CP变成了AP。多个Master节点通过数据分片和数据冗余，Redis具有了真正的分布式能力，某个结点挂了的话，因为数据在其他结点上有备份，所以其他结点顶上来就可以继续提供服务，保证了**Availability**。但是如果某一个Master挂了，数据还没有同步，那么就会出现**数据不一致**。



## 如何理解幂等，项目中幂等如何做？

任意多次执行所产生的影响均与一次执行的影响相同，java中，通常指接口调用多次和调用一次所造成的影响是一样的。

在分布式系统中，可能由于网络问题造成重试操作，需要服务保证幂等。

### 实现幂等

前端：

对于有交互的方式，可以在前端过滤一部分，如防止表单重复提交，按钮置灰，隐藏，不可点击等方式。但是这对普通用户有效，不能阻止直接调用接口，实现多次调用。

后端：

**数据库唯一性校验**：使用数据库主键的唯一约束，在操作时传过来一个唯一id，插入时如果已经执行过那么肯定会报错，这个时候直接报错回滚就行，比较简单粗暴。

**状态机**：通常业务系统都会存在不同的状态，状态之间是有联系 或者先后关系的，可以通过状态字段来保证操作不会造成影响。比如单据审批状态，**更新状态时加上状态判断。**

**Token机制**：调用方在调用接口的时候先向后端请求一个全局ID（TOKEN），请求的时候携带这个全局ID一起请求，后端需要对这个全局ID校验来保证幂等操作。

![image-20210508002232776](assets/image-20210508002232776.png)



## 反射能获取啥？能否获取参数名称、参数类型？

应该可以吧，待测试



## Collections.sort 底层排序的方式？

Arrays.sort（）







## 两个有序的list，求交集

retainall？

stream流遍历，判断list1 是否包含当前元素，如果包含则collect.tolist



# 微服务相关（内推的哥们说的考察的多，熔断、限流、降级等）

## 什么是微服务

微服务的概念是相对于传统的单体服务而言，微服务化的核心就是将传统的一站式应用，根据不同的业务拆分成一个一个的服务，彻底地去耦合,每一个微服务提供单个业务功能的服务，每个微服务可以根据业务采取不同的语言，一个服务做一件事，从技术角度看就是一种小而独立的处理过程，类似进程概念，能够自行单独启动或销毁，拥有自己独立的数据库。拆分后系统更加的灵活，扩展项更强。但是服务的复杂度也随之上升。

## 分布式系统面临的问题

高可用问题，不同的服务总有不可用的时候，如何做好系统得高可用。

CAP问题

数据的一致性问题，保证数据的最终一致性

服务雪崩：在微服务调用链路上，某一个服务不可用，导致调用它的上游服务接连的阻塞，从而导致大面积服务不可用的情况，造成级联故障。

**造成服务雪崩的原因：**

流量激增，异常流量，导致系统负载升高（项目中的计算类服务，由于用户不断上传记录，导致不停调用计算服务，发送到mq，计算服务一直消费，导致CPU飙升，导致其他服务调用时发生阻塞，响应严重变慢）解决：联系运维加资源扩容，应对大量计算服务，之后进行资源隔离，将计算服务单独拆分，不要影响其他服务，加入mq限流，削峰，排队消费，数据校验去重，幂等操作，避免重复计算。

缓存穿透：不停请求的数据库，返回临时缓存值，避免大量访问数据库。

程序bug：修复bug，紧急发布上线

数据库瓶颈：sql优化，硬件升级



## 什么是熔断、什么是降级

https://www.cnblogs.com/dalianpai/p/14389421.html

服务熔断：类别电路的断路器，当某个服务的响应时间太长或者失败次数太多，会进行熔断，访问该服务的请求会直接快速失败，不会继续请求，避免发生请求一直阻塞，导致服务器资源被沾满的情况。

SpringCloud 采用Hystrix做熔断处理，使用注解@HystrixCommand。

当失败的调用到一定阈值，缺省是5秒内20次调用失败就会启动熔断机制。Hystrix熔断器打开后，所以的请求都会快速失败，当过了一定时间后默认5s，开关会处于半开状态，意味着会尝试放过部分请求检测服务是否恢复正常，如果正常那么就关闭断路器。

**Hystrix可以指定熔断后的兜底处理，返回自定义的处理方案。**

服务降级：

指的是系统中一般分为0级系统，最重要的，和1、2、3级的次要系统，在发生服务雪崩时，可以对部分服务进行降级处理，不访问次要服务，节省资源，保证主要系统的正常访问。

或者是下游服务不可用时，调用方直接调用本地的兜底策略进行降级，fastback

熔断属于服务降级的一种策略。

## 熔断、限流、降级的区别

熔断强调的是服务之间的调用能实现自我恢复的状态；

限流是从系统的流量入口考虑，从进入的流量上进行限制，达到保护系统的作用；

降级，是从系统内部的平级服务或者业务的维度考虑，流量大了，可以干掉一些，保护其他正常使用；
熔断是降级方式的一种；

降级又是限流的一种方式；

三者都是为了通过一定的方式去保护流量过大时，保护系统的手段。保护系统资源，保证服务能够正常响应

## 限流的策略

固定、滑动时间窗口限流：在指定的时间段、滑动窗口时间内，配置一个限流规则，请求数不能超过多少，超过了就直接拒绝。使用计数器进行累计，时间到了就清零。（无法应对突发流量）

令牌桶、漏桶限流算法：

1. 接口限制 t 秒内最大访问次数为 n，则每隔 t/n 秒会放一个 token 到桶中；
2. 桶中最多可以存放 b 个 token，如果 token 到达时令牌桶已经满了，那么这个 token 会被丢弃；
3. 接口请求会先从令牌桶中取 token，拿到 token 则处理接口请求，拿不到 token 则执行限流。
4. 不需要单独服务去存放token，在获取token时根据时间差算出需要放入多少个，一次性放入即可。

**或者根据热点数据预测，分发到下游系统中，实现预热通，增加放入token 的速率，增加放入的token数量等，应对突发流量？？**

支持一次性取多个令牌出来。

### 分布式限流

上面所讲的是单机限流，在集群部署中，一个服务部署在多个服务器中，对单机单个服务进行限流。

而分布式限流指的是提供**服务级的限流**，限制对微服务集群的访问频率，比如限制 A 调用方每分钟最多请求 1 万次“用户服务”，分布式限流既可以使用单机限流算法也可以使用分布式限流算法。

需要一个中心化存储，使用Redis计数器记录限流次数，判断是否限流。

### 分布式限流架构

gateway 网关层统一限流

通过部署限流服务，请求rpc接口判断是否进行限流

耦合到服务内部，使用切面编程实现限流（使用redis中心化存储技术器）

## **Hystrix断路器**

微服务架构中，对服务间调用超时、故障进行容错、限流、降级、熔断处理。

对依赖服务调用时出现的延迟和失败进行控制和容错

在复杂的分布式系统中，阻止某一个依赖服务的故障在整个系统中蔓延，级联故障

提供fail-fast（快速失败）和快速恢复的支持

提供fallback优雅降级的支持 ，兜底策略

支持近实时的监控、报警及运维操作



## 分布式系统得好处及缺点

- 每个单独的服务足够小，能够专注于每一个领域，开发效率高
- 服务更加灵活，可以根据业务需要采用不同的语言和框架
- 开发迅速，部署简单，发布服务不会影响其他服务
- 扩展性更强，易于集成第三方框架或者技术
- 能够提高系统得高可用、高并发，提升系统得性能





- CAP问题，根据业务需要，选择高可用or强一致性
- 分布式系统引入的系统复杂度，引入的起它中间件，增加了系统复杂度
- 服务治理给运维带来压力，运维能力的挑战（引出了后来的devops）
- 服务监控更加重要，便于问题定位，日志分析、链路追踪、故障定位
- 数据一致性，分布式事务，复杂度提高
- 服务间的通行成本，重试机制，幂等保证，链路耗时等

## 服务注册中心 eureka or zookeeper

euruka 是**ap  高可用性 ** 部分节点挂掉不影响使用，还是可以提供服务，但是服务注册列表可能是未同步的旧信息。

zookeeper是 **cp  强一致性**  主节点挂掉后，选举过程中会停止对外服务，选择成功才进行服务，保证服务的强一致性

根据业务需要自行选择

Eureka自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况：

1. Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务
2. Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上(即保证当前节点依然可用)
3. 当网络稳定时，当前实例新的注册信息会被同步到其它节点中





